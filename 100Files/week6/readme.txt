# This is the readme for week 6 and how to operaipeline.pyPython 3.8.3dir/week6The purpose of this script is to be able to parse out pooled data from various sources, and correctly do the following:1.)Properly attach them to Barcode2.)Clear barcode from fastq reads3.)Account for degradation of signal and only work with data that meants qc standard ( in this case the occurance of two reads that had a quality score of F or D)4.)Create trimmed fastq files from cleaned data that meats qc and is properly tagged5.)Create an index from a reference sequence in order to align newly trimmed fastq files6.)Processed fastq by utilizing samtools to convert from fastq>sam>bam>sorted bam> and index those7.)Keep a clean workspace while transfering end product to main directory and elimitating intermediary steps8.)Pile those sequences to reference to determine SNPs9.) Properly ID those by comparing to WT (reference sequence)10.) Properly and clearly convey those resultsIn command line make sure that the following files are present:pipeline.pyharrington_clinical_data.txtdgorgon_reference.fahawkins_pooled_sequences.fastqmust have installedbwasamtoolsIn order to run this script write the code below python pipeline.py -c harrington_clinical_data.txt  -rs dgorgon_reference.fa -fq hawkins_pooled_sequences.fastqOutputs: Directories produced:fastqs      # this will contain an equal numbers as clinical trialsbams	    # this will contain 2x the number of clinical trials since it will include BAM and BMA.BAI files which are pairedbwaindex	# these are all the files produced from when bwa is indexed			__pycache__ # this gets produced to help with speed				Files in parent directory:report.txt
